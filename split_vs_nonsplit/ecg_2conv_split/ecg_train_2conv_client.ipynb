{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Split 1D-CNN Client Side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is the server part of ECG split 1D-CNN model for **single** client and a server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'CIFAR10'\n",
    "\n",
    "import os\n",
    "import struct\n",
    "import socket\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ECG dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Loaded CIFAR10 datasets with batch size 32\n"
     ]
    }
   ],
   "source": [
    "if mode == 'ECG':\n",
    "    class ECG(Dataset):\n",
    "        def __init__(self, train=True):\n",
    "            if train:\n",
    "                with h5py.File(os.path.join('../../', 'mitdb', 'train_ecg.hdf5'), 'r') as hdf:\n",
    "                    self.x = hdf['x_train'][:]\n",
    "                    self.y = hdf['y_train'][:]\n",
    "            else:\n",
    "                with h5py.File(os.path.join('../../', 'mitdb', 'test_ecg.hdf5'), 'r') as hdf:\n",
    "                    self.x = hdf['x_test'][:]\n",
    "                    self.y = hdf['y_test'][:]\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.x)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            return torch.tensor(self.x[idx], dtype=torch.float), torch.tensor(self.y[idx])\n",
    "        \n",
    "    batch_size = 32\n",
    "    train_dataset = ECG(train=True)\n",
    "    test_dataset = ECG(train=False)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    total_batch = len(train_loader)\n",
    "    print(total_batch)\n",
    "elif mode == 'CIFAR10':\n",
    "    root_path = '../../data/'  # Replace with actual path to CIFAR10 data\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "    train_dataset = CIFAR10(root=root_path, train=True, download=True, transform=transform)\n",
    "    test_dataset = CIFAR10(root=root_path, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    print(\"Loaded CIFAR10 datasets with batch size\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'ECG':\n",
    "    class EcgClient(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(EcgClient, self).__init__()\n",
    "            self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "            self.relu1 = nn.ReLU()\n",
    "            self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "            self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "            self.relu2 = nn.ReLU()\n",
    "            self.pool2 = nn.MaxPool1d(2)  # 32 x 16\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu1(x)\n",
    "            x = self.pool1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.relu2(x)\n",
    "            x = self.pool2(x)\n",
    "            x = x.view(-1, 32 * 16)\n",
    "            return x\n",
    "elif mode == 'CIFAR10':\n",
    "    class EcgClient(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(EcgClient, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 16, 7, padding=3)\n",
    "            self.relu1 = nn.LeakyReLU()\n",
    "            self.pool1 = nn.MaxPool2d(2)\n",
    "            self.conv2 = nn.Conv2d(16, 16, 5, padding=2)\n",
    "            self.relu2 = nn.LeakyReLU()\n",
    "            self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu1(x)\n",
    "            x = self.pool1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.relu2(x)\n",
    "            x = self.pool2(x)\n",
    "            x = x.view(-1, 8 * 8 * 16)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "torch.cuda.get_device_name(0)\n",
    "assert('cuda' in device.type)\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "ecg_client = EcgClient()\n",
    "ecg_client.to(device)\n",
    "\n",
    "checkpoint = torch.load(f\"../ecg_2conv/init_weight{mode}.pth\")\n",
    "ecg_client.conv1.weight.data = checkpoint[\"conv1.weight\"]\n",
    "ecg_client.conv1.bias.data = checkpoint[\"conv1.bias\"]\n",
    "ecg_client.conv2.weight.data = checkpoint[\"conv2.weight\"]\n",
    "ecg_client.conv2.bias.data = checkpoint[\"conv2.bias\"]\n",
    "epoch = 400\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "optimizer = Adam(ecg_client.parameters(), lr=lr)\n",
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = struct.pack('>I', len(msg)) + msg\n",
    "    sock.sendall(msg)\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    return recvall(sock, msglen)\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data\n",
    "host = 'localhost'\n",
    "port = 10080\n",
    "max_recv = 4096\n",
    "s = socket.socket()\n",
    "s.connect((host, port))\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563\n",
      "Epoch 1 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:09, 157.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with batch\n",
      "loss: 2.1007, acc: 35.19% / test_loss: 0.4108, test_acc: 40.37%\n",
      "Epoch 2 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:09, 161.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with batch\n",
      "loss: 2.0157, acc: 44.05% / test_loss: 0.3963, test_acc: 47.86%\n",
      "Epoch 3 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:09, 159.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with batch\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "print(len(train_loader))\n",
    "for e in range(epoch):\n",
    "    print(\"Epoch {} - \".format(e+1), end='')\n",
    "    \n",
    "    for _, batch in tqdm(enumerate(train_loader)):\n",
    "        x, label = batch\n",
    "        x, label = x.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        ecg_client = ecg_client.to(device)\n",
    "        output = ecg_client(x)\n",
    "        client_output = output.clone().detach().requires_grad_(True)\n",
    "        msg = {\n",
    "            'client_output': client_output,\n",
    "            'label': label\n",
    "        }\n",
    "        msg = pickle.dumps(msg)\n",
    "        send_msg(s, msg)\n",
    "        msg = recv_msg(s)\n",
    "        client_grad = pickle.loads(msg)\n",
    "        output.backward(client_grad)\n",
    "        optimizer.step()\n",
    "    print('done with batch')\n",
    "            \n",
    "    with torch.no_grad():  # calculate test accuracy\n",
    "        for _, batch in enumerate(test_loader):\n",
    "            x, label = batch\n",
    "            x, label = x.to(device), label.to(device)\n",
    "            client_output = ecg_client(x)\n",
    "            msg = {\n",
    "                'client_output': client_output,\n",
    "                'label': label\n",
    "            }\n",
    "            msg = pickle.dumps(msg)\n",
    "            send_msg(s, msg)\n",
    "    \n",
    "    msg = recv_msg(s)\n",
    "    train_test_status = pickle.loads(msg)\n",
    "    print(train_test_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training!\n",
      "Result is on the server side.\n"
     ]
    }
   ],
   "source": [
    "print('Finished Training!')\n",
    "print('Result is on the server side.')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

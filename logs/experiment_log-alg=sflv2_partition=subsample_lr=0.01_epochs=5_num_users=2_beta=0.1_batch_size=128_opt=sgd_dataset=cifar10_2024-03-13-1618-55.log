03-13 16:18 INFO     cuda
03-13 16:18 INFO     Command Line Arguments: 
{
    "epochs": 5,
    "comm_round": 8,
    "sample_fraction": 1.0,
    "alpha": 0.1,
    "dataset": "cifar10",
    "datadir": "../data/",
    "partition": "subsample",
    "alg": "sflv2",
    "model": "resnet-18",
    "n_parties": 2,
    "lr": 0.01,
    "mu": 1,
    "std_coeff": 2.5,
    "unif_coeff": 0.5,
    "batch_size": 128,
    "load_first_net": 1,
    "pool_option": "FIFO",
    "model_buffer_size": 1,
    "optimizer": "sgd",
    "simp_width": 1,
    "out_dim": 256,
    "reg": 0.0005,
    "temperature": 0.5,
    "logdir": "./",
    "log_file_name": "logs/experiment_log-alg=sflv2_partition=subsample_lr=0.01_epochs=5_num_users=2_beta=0.1_batch_size=128_opt=sgd_dataset=cifar10_2024-03-13-1618-55",
    "seed": 42,
    "device": "cuda",
    "multiprocessing": 0
}
03-13 16:18 INFO     Data statistics: {0: {2: 218, 3: 1079, 4: 996, 6: 6, 7: 460, 8: 1142, 9: 1099}, 1: {0: 1452, 1: 1430, 2: 1162, 3: 1, 4: 193, 5: 1494, 6: 1397, 7: 871}}
03-13 16:18 INFO     in comm round:0
03-13 16:18 INFO     Training network 0 n_training: 5000
03-13 16:18 INFO     Training network 0
03-13 16:18 INFO     n_training: 39
03-13 16:19 INFO     Client: 0 Epoch: 0 Loss: 1.59615835471031
03-13 16:19 INFO     Client: 0 Epoch: 1 Loss: 1.0763016373683245
03-13 16:19 INFO     Client: 0 Epoch: 2 Loss: 0.9888082666274829
03-13 16:19 INFO     Client: 0 Epoch: 3 Loss: 0.8897156684826582
03-13 16:19 INFO     Client: 0 Epoch: 4 Loss: 0.827147459372496
03-13 16:19 INFO      ** Client: 0 Training complete **
03-13 16:19 INFO     Training network 1 n_training: 8000
03-13 16:19 INFO     Training network 1
03-13 16:19 INFO     n_training: 62
03-13 16:19 INFO     Client: 1 Epoch: 0 Loss: 1.4904501130503993
03-13 16:19 INFO     Client: 1 Epoch: 1 Loss: 1.059379767987036
03-13 16:19 INFO     Client: 1 Epoch: 2 Loss: 0.90774838674453
03-13 16:19 INFO     Client: 1 Epoch: 3 Loss: 0.8425992640756792
03-13 16:19 INFO     Client: 1 Epoch: 4 Loss: 0.7547370310752622
03-13 16:19 INFO      ** Client: 1 Training complete **
03-13 16:19 INFO     global n_training: 390
03-13 16:19 INFO     global n_test: 79
03-13 16:19 INFO     >> Global Model Train accuracy: 0.117528
03-13 16:19 INFO     >> Global Model Test accuracy: 0.119900
03-13 16:19 INFO     >> Global Model Train loss: 2.506559
03-13 16:19 INFO     in comm round:1
03-13 16:19 INFO     Training network 0 n_training: 5000
03-13 16:19 INFO     Training network 0
03-13 16:19 INFO     n_training: 39
03-13 16:19 INFO     Client: 0 Epoch: 0 Loss: 0.9730478326479594
03-13 16:19 INFO     Client: 0 Epoch: 1 Loss: 0.8016822567352881
03-13 16:19 INFO     Client: 0 Epoch: 2 Loss: 0.7350142002105713
03-13 16:19 INFO     Client: 0 Epoch: 3 Loss: 0.6860364820712652
03-13 16:19 INFO     Client: 0 Epoch: 4 Loss: 0.6351290796047602
03-13 16:19 INFO      ** Client: 0 Training complete **
03-13 16:19 INFO     Training network 1 n_training: 8000
03-13 16:19 INFO     Training network 1
03-13 16:19 INFO     n_training: 62
03-13 16:19 INFO     Client: 1 Epoch: 0 Loss: 0.8727640884537851
03-13 16:19 INFO     Client: 1 Epoch: 1 Loss: 0.7384741796601203
03-13 16:19 INFO     Client: 1 Epoch: 2 Loss: 0.6650355515941497
03-13 16:19 INFO     Client: 1 Epoch: 3 Loss: 0.6317479076885408
03-13 16:19 INFO     Client: 1 Epoch: 4 Loss: 0.5671220392950119
03-13 16:19 INFO      ** Client: 1 Training complete **
03-13 16:19 INFO     global n_training: 390
03-13 16:19 INFO     global n_test: 79
03-13 16:19 INFO     >> Global Model Train accuracy: 0.402544
03-13 16:19 INFO     >> Global Model Test accuracy: 0.421900
03-13 16:19 INFO     >> Global Model Train loss: 1.604395
03-13 16:19 INFO     in comm round:2
03-13 16:19 INFO     Training network 0 n_training: 5000
03-13 16:19 INFO     Training network 0
03-13 16:19 INFO     n_training: 39
03-13 16:19 INFO     Client: 0 Epoch: 0 Loss: 0.7311086715796055
03-13 16:20 INFO     Client: 0 Epoch: 1 Loss: 0.6399715114862491
03-13 16:20 INFO     Client: 0 Epoch: 2 Loss: 0.5574084459206997
03-13 16:20 INFO     Client: 0 Epoch: 3 Loss: 0.5171042673098736
03-13 16:20 INFO     Client: 0 Epoch: 4 Loss: 0.47738473690473116
03-13 16:20 INFO      ** Client: 0 Training complete **
03-13 16:20 INFO     Training network 1 n_training: 8000
03-13 16:20 INFO     Training network 1
03-13 16:20 INFO     n_training: 62
03-13 16:20 INFO     Client: 1 Epoch: 0 Loss: 0.6745847074254867
03-13 16:20 INFO     Client: 1 Epoch: 1 Loss: 0.5802813830875582
03-13 16:20 INFO     Client: 1 Epoch: 2 Loss: 0.531096316633686
03-13 16:20 INFO     Client: 1 Epoch: 3 Loss: 0.4837421693148152
03-13 16:20 INFO     Client: 1 Epoch: 4 Loss: 0.4496946998180882
03-13 16:20 INFO      ** Client: 1 Training complete **
03-13 16:20 INFO     global n_training: 390
03-13 16:20 INFO     global n_test: 79
03-13 16:20 INFO     >> Global Model Train accuracy: 0.458534
03-13 16:20 INFO     >> Global Model Test accuracy: 0.461400
03-13 16:20 INFO     >> Global Model Train loss: 1.457169
03-13 16:20 INFO     in comm round:3
03-13 16:20 INFO     Training network 0 n_training: 5000
03-13 16:20 INFO     Training network 0
03-13 16:20 INFO     n_training: 39
03-13 16:20 INFO     Client: 0 Epoch: 0 Loss: 0.536332348982493
03-13 16:20 INFO     Client: 0 Epoch: 1 Loss: 0.4723828129279308
03-13 16:20 INFO     Client: 0 Epoch: 2 Loss: 0.4219544407648918
03-13 16:20 INFO     Client: 0 Epoch: 3 Loss: 0.38133095357662594
03-13 16:20 INFO     Client: 0 Epoch: 4 Loss: 0.3402312573714134
03-13 16:20 INFO      ** Client: 0 Training complete **
03-13 16:20 INFO     Training network 1 n_training: 8000
03-13 16:20 INFO     Training network 1
03-13 16:20 INFO     n_training: 62
03-13 16:20 INFO     Client: 1 Epoch: 0 Loss: 0.5191319979006245
03-13 16:20 INFO     Client: 1 Epoch: 1 Loss: 0.4669756504797166
03-13 16:20 INFO     Client: 1 Epoch: 2 Loss: 0.42267484241916287
03-13 16:20 INFO     Client: 1 Epoch: 3 Loss: 0.39180958871879884
03-13 16:20 INFO     Client: 1 Epoch: 4 Loss: 0.36669030208741465
03-13 16:20 INFO      ** Client: 1 Training complete **
03-13 16:20 INFO     global n_training: 390
03-13 16:20 INFO     global n_test: 79
03-13 16:20 INFO     >> Global Model Train accuracy: 0.594892
03-13 16:20 INFO     >> Global Model Test accuracy: 0.606700
03-13 16:20 INFO     >> Global Model Train loss: 1.075572
03-13 16:20 INFO     in comm round:4
03-13 16:20 INFO     Training network 0 n_training: 5000
03-13 16:20 INFO     Training network 0
03-13 16:20 INFO     n_training: 39
03-13 16:20 INFO     Client: 0 Epoch: 0 Loss: 0.45025698114664126
03-13 16:20 INFO     Client: 0 Epoch: 1 Loss: 0.3672847793652461
03-13 16:20 INFO     Client: 0 Epoch: 2 Loss: 0.32103885748447514
03-13 16:20 INFO     Client: 0 Epoch: 3 Loss: 0.27691993270164883
03-13 16:21 INFO     Client: 0 Epoch: 4 Loss: 0.2560322953340335
03-13 16:21 INFO      ** Client: 0 Training complete **
03-13 16:21 INFO     Training network 1 n_training: 8000
03-13 16:21 INFO     Training network 1
03-13 16:21 INFO     n_training: 62
03-13 16:21 INFO     Client: 1 Epoch: 0 Loss: 0.40873914524432153
03-13 16:21 INFO     Client: 1 Epoch: 1 Loss: 0.3569316212688723
03-13 16:21 INFO     Client: 1 Epoch: 2 Loss: 0.33467731865183
03-13 16:21 INFO     Client: 1 Epoch: 3 Loss: 0.30604234770421057
03-13 16:21 INFO     Client: 1 Epoch: 4 Loss: 0.2890169067728904
03-13 16:21 INFO      ** Client: 1 Training complete **
03-13 16:21 INFO     global n_training: 390
03-13 16:21 INFO     global n_test: 79
03-13 16:21 INFO     >> Global Model Train accuracy: 0.601042
03-13 16:21 INFO     >> Global Model Test accuracy: 0.612000
03-13 16:21 INFO     >> Global Model Train loss: 1.099178
03-13 16:21 INFO     in comm round:5
03-13 16:21 INFO     Training network 0 n_training: 5000
03-13 16:21 INFO     Training network 0
03-13 16:21 INFO     n_training: 39
03-13 16:21 INFO     Client: 0 Epoch: 0 Loss: 0.3188909678122936
03-13 16:21 INFO     Client: 0 Epoch: 1 Loss: 0.2729213631305939
03-13 16:21 INFO     Client: 0 Epoch: 2 Loss: 0.27017962626921826
03-13 16:21 INFO     Client: 0 Epoch: 3 Loss: 0.22969839779230264
03-13 16:21 INFO     Client: 0 Epoch: 4 Loss: 0.19736670702695847
03-13 16:21 INFO      ** Client: 0 Training complete **
03-13 16:21 INFO     Training network 1 n_training: 8000
03-13 16:21 INFO     Training network 1
03-13 16:21 INFO     n_training: 62
03-13 16:21 INFO     Client: 1 Epoch: 0 Loss: 0.36032322145277457
03-13 16:21 INFO     Client: 1 Epoch: 1 Loss: 0.2874226127901385
03-13 16:21 INFO     Client: 1 Epoch: 2 Loss: 0.27810796302172447
03-13 16:21 INFO     Client: 1 Epoch: 3 Loss: 0.25985813741722413
03-13 16:21 INFO     Client: 1 Epoch: 4 Loss: 0.23264408303845313
03-13 16:21 INFO      ** Client: 1 Training complete **
03-13 16:21 INFO     global n_training: 390
03-13 16:21 INFO     global n_test: 79
03-13 16:21 INFO     >> Global Model Train accuracy: 0.626422
03-13 16:21 INFO     >> Global Model Test accuracy: 0.627100
03-13 16:21 INFO     >> Global Model Train loss: 0.970103
03-13 16:21 INFO     in comm round:6
03-13 16:21 INFO     Training network 0 n_training: 5000
03-13 16:21 INFO     Training network 0
03-13 16:21 INFO     n_training: 39
03-13 16:21 INFO     Client: 0 Epoch: 0 Loss: 0.2955926943283815
03-13 16:21 INFO     Client: 0 Epoch: 1 Loss: 0.2287226283015349
03-13 16:21 INFO     Client: 0 Epoch: 2 Loss: 0.22112445609691816
03-13 16:21 INFO     Client: 0 Epoch: 3 Loss: 0.18506370962430269
03-13 16:21 INFO     Client: 0 Epoch: 4 Loss: 0.17266697742235967
03-13 16:21 INFO      ** Client: 0 Training complete **
03-13 16:21 INFO     Training network 1 n_training: 8000
03-13 16:21 INFO     Training network 1
03-13 16:21 INFO     n_training: 62
03-13 16:21 INFO     Client: 1 Epoch: 0 Loss: 0.2868296133895074
03-13 16:21 INFO     Client: 1 Epoch: 1 Loss: 0.24656182323252002
03-13 16:22 INFO     Client: 1 Epoch: 2 Loss: 0.2250694115796397
03-13 16:22 INFO     Client: 1 Epoch: 3 Loss: 0.2099343567125259
03-13 16:22 INFO     Client: 1 Epoch: 4 Loss: 0.19609425421203336
03-13 16:22 INFO      ** Client: 1 Training complete **
03-13 16:22 INFO     global n_training: 390
03-13 16:22 INFO     global n_test: 79
03-13 16:22 INFO     >> Global Model Train accuracy: 0.654928
03-13 16:22 INFO     >> Global Model Test accuracy: 0.646000
03-13 16:22 INFO     >> Global Model Train loss: 0.920933
03-13 16:22 INFO     in comm round:7
03-13 16:22 INFO     Training network 0 n_training: 5000
03-13 16:22 INFO     Training network 0
03-13 16:22 INFO     n_training: 39
03-13 16:22 INFO     Client: 0 Epoch: 0 Loss: 0.2331125250993631
03-13 16:22 INFO     Client: 0 Epoch: 1 Loss: 0.1810761401668573
03-13 16:22 INFO     Client: 0 Epoch: 2 Loss: 0.18491039310510343
03-13 16:22 INFO     Client: 0 Epoch: 3 Loss: 0.1589516716507765
03-13 16:22 INFO     Client: 0 Epoch: 4 Loss: 0.14205827153263947
03-13 16:22 INFO      ** Client: 0 Training complete **
03-13 16:22 INFO     Training network 1 n_training: 8000
03-13 16:22 INFO     Training network 1
03-13 16:22 INFO     n_training: 62
03-13 16:22 INFO     Client: 1 Epoch: 0 Loss: 0.23617453128099442
03-13 16:22 INFO     Client: 1 Epoch: 1 Loss: 0.21013233942850942
03-13 16:22 INFO     Client: 1 Epoch: 2 Loss: 0.1931244836699578
03-13 16:22 INFO     Client: 1 Epoch: 3 Loss: 0.17533339217545524
03-13 16:22 INFO     Client: 1 Epoch: 4 Loss: 0.15952604648567015
03-13 16:22 INFO      ** Client: 1 Training complete **
03-13 16:22 INFO     global n_training: 390
03-13 16:22 INFO     global n_test: 79
03-13 16:22 INFO     >> Global Model Train accuracy: 0.667087
03-13 16:22 INFO     >> Global Model Test accuracy: 0.665100
03-13 16:22 INFO     >> Global Model Train loss: 0.889273
03-13 16:22 INFO     Starting Fine Tuning...
03-13 16:22 INFO     Training network 0
03-13 16:22 INFO     n_training: 39
03-13 16:22 INFO     Client: 0 Epoch: 0 Loss: 0.10772278102544638
03-13 16:22 INFO     Client: 0 Epoch: 1 Loss: 0.1010516735796745
03-13 16:22 INFO     Client: 0 Epoch: 2 Loss: 0.11385207565931174
03-13 16:22 INFO     Client: 0 Epoch: 3 Loss: 0.11973865521259797
03-13 16:22 INFO     Client: 0 Epoch: 4 Loss: 0.10389073450977986
03-13 16:22 INFO      ** Client: 0 Training complete **

03-13 16:06 INFO     cuda
03-13 16:06 INFO     Command Line Arguments: 
{
    "epochs": 5,
    "comm_round": 8,
    "sample_fraction": 1.0,
    "alpha": 0.1,
    "dataset": "cifar10",
    "datadir": "../data/",
    "partition": "subsample",
    "alg": "sflv2",
    "model": "resnet-18",
    "n_parties": 2,
    "lr": 0.01,
    "mu": 1,
    "std_coeff": 2.5,
    "unif_coeff": 0.5,
    "batch_size": 128,
    "load_first_net": 1,
    "pool_option": "FIFO",
    "model_buffer_size": 1,
    "optimizer": "sgd",
    "simp_width": 1,
    "out_dim": 256,
    "reg": 0.0005,
    "temperature": 0.5,
    "logdir": "./",
    "log_file_name": "logs/experiment_log-alg=sflv2_partition=subsample_lr=0.01_epochs=5_num_users=2_beta=0.1_batch_size=128_opt=sgd_dataset=cifar10_2024-03-13-1606-39",
    "seed": 42,
    "device": "cuda",
    "multiprocessing": 0
}
03-13 16:06 INFO     Data statistics: {0: {2: 218, 3: 1079, 4: 996, 6: 6, 7: 460, 8: 1142, 9: 1099}, 1: {0: 1452, 1: 1430, 2: 1162, 3: 1, 4: 193, 5: 1494, 6: 1397, 7: 871}}
03-13 16:06 INFO     in comm round:0
03-13 16:06 INFO     Training network 0 n_training: 5000
03-13 16:06 INFO     Training network 0
03-13 16:06 INFO     n_training: 39
03-13 16:06 INFO     Client: 0 Epoch: 0 Loss: 1.6027366136893249
03-13 16:06 INFO     Client: 0 Epoch: 1 Loss: 1.0784692917114649
03-13 16:06 INFO     Client: 0 Epoch: 2 Loss: 0.9729859767816006
03-13 16:06 INFO     Client: 0 Epoch: 3 Loss: 0.8952301832345816
03-13 16:06 INFO     Client: 0 Epoch: 4 Loss: 0.8252084071819599
03-13 16:06 INFO      ** Client: 0 Training complete **
03-13 16:06 INFO     Training network 1 n_training: 8000
03-13 16:06 INFO     Training network 1
03-13 16:06 INFO     n_training: 62
03-13 16:06 INFO     Client: 1 Epoch: 0 Loss: 1.5024130325163565
03-13 16:07 INFO     Client: 1 Epoch: 1 Loss: 1.0517036357233602
03-13 16:07 INFO     Client: 1 Epoch: 2 Loss: 0.9047486493664403
03-13 16:07 INFO     Client: 1 Epoch: 3 Loss: 0.8232331372076466
03-13 16:07 INFO     Client: 1 Epoch: 4 Loss: 0.7462149262428284
03-13 16:07 INFO      ** Client: 1 Training complete **
03-13 16:07 INFO     global n_training: 390
03-13 16:07 INFO     global n_test: 79
03-13 16:07 INFO     >> Global Model Train accuracy: 0.151623
03-13 16:07 INFO     >> Global Model Test accuracy: 0.158600
03-13 16:07 INFO     >> Global Model Train loss: 2.404654
03-13 16:07 INFO     in comm round:1
03-13 16:07 INFO     Training network 0 n_training: 5000
03-13 16:07 INFO     Training network 0
03-13 16:07 INFO     n_training: 39
03-13 16:07 INFO     Client: 0 Epoch: 0 Loss: 0.9692112528360807
03-13 16:07 INFO     Client: 0 Epoch: 1 Loss: 0.8253143506172376
03-13 16:07 INFO     Client: 0 Epoch: 2 Loss: 0.7229452652808948
03-13 16:07 INFO     Client: 0 Epoch: 3 Loss: 0.6879334648450216
03-13 16:07 INFO     Client: 0 Epoch: 4 Loss: 0.6350616461191422
03-13 16:07 INFO      ** Client: 0 Training complete **
03-13 16:07 INFO     Training network 1 n_training: 8000
03-13 16:07 INFO     Training network 1
03-13 16:07 INFO     n_training: 62
03-13 16:07 INFO     Client: 1 Epoch: 0 Loss: 0.873516526914412
03-13 16:07 INFO     Client: 1 Epoch: 1 Loss: 0.7351694135896621
03-13 16:07 INFO     Client: 1 Epoch: 2 Loss: 0.6628209020822279
03-13 16:07 INFO     Client: 1 Epoch: 3 Loss: 0.6054630101688446
03-13 16:07 INFO     Client: 1 Epoch: 4 Loss: 0.5544846226130763
03-13 16:07 INFO      ** Client: 1 Training complete **
03-13 16:07 INFO     global n_training: 390
03-13 16:07 INFO     global n_test: 79
03-13 16:07 INFO     >> Global Model Train accuracy: 0.352183
03-13 16:07 INFO     >> Global Model Test accuracy: 0.356400
03-13 16:07 INFO     >> Global Model Train loss: 1.690669
03-13 16:07 INFO     in comm round:2
03-13 16:07 INFO     Training network 0 n_training: 5000
03-13 16:07 INFO     Training network 0
03-13 16:07 INFO     n_training: 39
03-13 16:07 INFO     Client: 0 Epoch: 0 Loss: 0.7342318617380582
03-13 16:07 INFO     Client: 0 Epoch: 1 Loss: 0.643070766559014
03-13 16:07 INFO     Client: 0 Epoch: 2 Loss: 0.5665214115228409
03-13 16:07 INFO     Client: 0 Epoch: 3 Loss: 0.5208499125945263
03-13 16:07 INFO     Client: 0 Epoch: 4 Loss: 0.4536889959604312
03-13 16:07 INFO      ** Client: 0 Training complete **
03-13 16:07 INFO     Training network 1 n_training: 8000
03-13 16:07 INFO     Training network 1
03-13 16:07 INFO     n_training: 62
03-13 16:07 INFO     Client: 1 Epoch: 0 Loss: 0.6675184917065405
03-13 16:07 INFO     Client: 1 Epoch: 1 Loss: 0.5706695337449351
03-13 16:07 INFO     Client: 1 Epoch: 2 Loss: 0.5164267108325036
03-13 16:08 INFO     Client: 1 Epoch: 3 Loss: 0.47805608136038624
03-13 16:08 INFO     Client: 1 Epoch: 4 Loss: 0.43558126375559836
03-13 16:08 INFO      ** Client: 1 Training complete **
03-13 16:08 INFO     global n_training: 390
03-13 16:08 INFO     global n_test: 79
03-13 16:08 INFO     >> Global Model Train accuracy: 0.435096
03-13 16:08 INFO     >> Global Model Test accuracy: 0.454500
03-13 16:08 INFO     >> Global Model Train loss: 1.516369
03-13 16:08 INFO     in comm round:3
03-13 16:08 INFO     Training network 0 n_training: 5000
03-13 16:08 INFO     Training network 0
03-13 16:08 INFO     n_training: 39
03-13 16:08 INFO     Client: 0 Epoch: 0 Loss: 0.5316590101290972
03-13 16:08 INFO     Client: 0 Epoch: 1 Loss: 0.48592068293155766
03-13 16:08 INFO     Client: 0 Epoch: 2 Loss: 0.41843345990547764
03-13 16:08 INFO     Client: 0 Epoch: 3 Loss: 0.36063708938085115
03-13 16:08 INFO     Client: 0 Epoch: 4 Loss: 0.35321714939215243
03-13 16:08 INFO      ** Client: 0 Training complete **
03-13 16:08 INFO     Training network 1 n_training: 8000
03-13 16:08 INFO     Training network 1
03-13 16:08 INFO     n_training: 62
03-13 16:08 INFO     Client: 1 Epoch: 0 Loss: 0.5145931460203663
03-13 16:08 INFO     Client: 1 Epoch: 1 Loss: 0.44979138335874
03-13 16:08 INFO     Client: 1 Epoch: 2 Loss: 0.4168491488502872
03-13 16:08 INFO     Client: 1 Epoch: 3 Loss: 0.38800845175020154
03-13 16:08 INFO     Client: 1 Epoch: 4 Loss: 0.36621668838685556
03-13 16:08 INFO      ** Client: 1 Training complete **
03-13 16:08 INFO     global n_training: 390
03-13 16:08 INFO     global n_test: 79
03-13 16:08 INFO     >> Global Model Train accuracy: 0.573317
03-13 16:08 INFO     >> Global Model Test accuracy: 0.581300
03-13 16:08 INFO     >> Global Model Train loss: 1.083271
03-13 16:08 INFO     in comm round:4
03-13 16:08 INFO     Training network 0 n_training: 5000
03-13 16:08 INFO     Training network 0
03-13 16:08 INFO     n_training: 39
03-13 16:08 INFO     Client: 0 Epoch: 0 Loss: 0.4566035882020608
03-13 16:08 INFO     Client: 0 Epoch: 1 Loss: 0.3604585650639656
03-13 16:08 INFO     Client: 0 Epoch: 2 Loss: 0.323310565107908
03-13 16:08 INFO     Client: 0 Epoch: 3 Loss: 0.2863283619666711
03-13 16:08 INFO     Client: 0 Epoch: 4 Loss: 0.2643155115537154
03-13 16:08 INFO      ** Client: 0 Training complete **
03-13 16:08 INFO     Training network 1 n_training: 8000
03-13 16:08 INFO     Training network 1
03-13 16:08 INFO     n_training: 62
03-13 16:08 INFO     Client: 1 Epoch: 0 Loss: 0.40189753328600236
03-13 16:08 INFO     Client: 1 Epoch: 1 Loss: 0.3541328000926202
03-13 16:08 INFO     Client: 1 Epoch: 2 Loss: 0.33350681465479637
03-13 16:08 INFO     Client: 1 Epoch: 3 Loss: 0.30117491656734097
03-13 16:08 INFO     Client: 1 Epoch: 4 Loss: 0.28090531234779664
03-13 16:08 INFO      ** Client: 1 Training complete **
03-13 16:08 INFO     global n_training: 390
03-13 16:08 INFO     global n_test: 79
03-13 16:09 INFO     >> Global Model Train accuracy: 0.582031
03-13 16:09 INFO     >> Global Model Test accuracy: 0.573500
03-13 16:09 INFO     >> Global Model Train loss: 1.106100
03-13 16:09 INFO     in comm round:5
03-13 16:09 INFO     Training network 0 n_training: 5000
03-13 16:09 INFO     Training network 0
03-13 16:09 INFO     n_training: 39
03-13 16:09 INFO     Client: 0 Epoch: 0 Loss: 0.359794856264041
03-13 16:09 INFO     Client: 0 Epoch: 1 Loss: 0.28491810766550213
03-13 16:09 INFO     Client: 0 Epoch: 2 Loss: 0.25756655136744183
03-13 16:09 INFO     Client: 0 Epoch: 3 Loss: 0.22740354102391463
03-13 16:09 INFO     Client: 0 Epoch: 4 Loss: 0.21735612933452314
03-13 16:09 INFO      ** Client: 0 Training complete **
03-13 16:09 INFO     Training network 1 n_training: 8000
03-13 16:09 INFO     Training network 1
03-13 16:09 INFO     n_training: 62
03-13 16:09 INFO     Client: 1 Epoch: 0 Loss: 0.35225536722329354
03-13 16:09 INFO     Client: 1 Epoch: 1 Loss: 0.28787127738037416
03-13 16:09 INFO     Client: 1 Epoch: 2 Loss: 0.27458296115359954
03-13 16:09 INFO     Client: 1 Epoch: 3 Loss: 0.2589594762652151
03-13 16:09 INFO     Client: 1 Epoch: 4 Loss: 0.23850887316849925
03-13 16:09 INFO      ** Client: 1 Training complete **
03-13 16:09 INFO     global n_training: 390
03-13 16:09 INFO     global n_test: 79
03-13 16:09 INFO     >> Global Model Train accuracy: 0.597256
03-13 16:09 INFO     >> Global Model Test accuracy: 0.599300
03-13 16:09 INFO     >> Global Model Train loss: 1.083588
03-13 16:09 INFO     in comm round:6
03-13 16:09 INFO     Training network 0 n_training: 5000
03-13 16:09 INFO     Training network 0
03-13 16:09 INFO     n_training: 39
03-13 16:09 INFO     Client: 0 Epoch: 0 Loss: 0.2810511913819191
03-13 16:09 INFO     Client: 0 Epoch: 1 Loss: 0.2181803286075592
03-13 16:09 INFO     Client: 0 Epoch: 2 Loss: 0.2295681039492289
03-13 16:09 INFO     Client: 0 Epoch: 3 Loss: 0.18917109511601618
03-13 16:09 INFO     Client: 0 Epoch: 4 Loss: 0.17732002719854698
03-13 16:09 INFO      ** Client: 0 Training complete **
03-13 16:09 INFO     Training network 1 n_training: 8000
03-13 16:09 INFO     Training network 1
03-13 16:09 INFO     n_training: 62
03-13 16:09 INFO     Client: 1 Epoch: 0 Loss: 0.30805223146753924
03-13 16:09 INFO     Client: 1 Epoch: 1 Loss: 0.25664333085859975
03-13 16:09 INFO     Client: 1 Epoch: 2 Loss: 0.22232440390413807
03-13 16:09 INFO     Client: 1 Epoch: 3 Loss: 0.21494923604111518

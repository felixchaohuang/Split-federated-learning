{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Split 1D-CNN Client Side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is the server part of ECG split 1D-CNN model for **single** client and a server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'CIFAR10'\n",
    "\n",
    "import os\n",
    "import struct\n",
    "import socket\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ECG dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Loaded CIFAR10 datasets with batch size 32\n"
     ]
    }
   ],
   "source": [
    "if mode == 'ECG':\n",
    "    class ECG(Dataset):\n",
    "        def __init__(self, train=True):\n",
    "            if train:\n",
    "                with h5py.File(os.path.join('../../', 'mitdb', 'train_ecg.hdf5'), 'r') as hdf:\n",
    "                    self.x = hdf['x_train'][:]\n",
    "                    self.y = hdf['y_train'][:]\n",
    "            else:\n",
    "                with h5py.File(os.path.join('../../', 'mitdb', 'test_ecg.hdf5'), 'r') as hdf:\n",
    "                    self.x = hdf['x_test'][:]\n",
    "                    self.y = hdf['y_test'][:]\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.x)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            return torch.tensor(self.x[idx], dtype=torch.float), torch.tensor(self.y[idx])\n",
    "        \n",
    "    batch_size = 32\n",
    "    train_dataset = ECG(train=True)\n",
    "    test_dataset = ECG(train=False)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    total_batch = len(train_loader)\n",
    "    print(total_batch)\n",
    "elif mode == 'CIFAR10':\n",
    "    root_path = '../../data/'  # Replace with actual path to CIFAR10 data\n",
    "\n",
    "    batch_size = 32\n",
    "    cifar10_mean = (0.485, 0.456, 0.406)\n",
    "    cifar10_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=cifar10_mean, std=cifar10_std)\n",
    "    ])\n",
    "    train_dataset = CIFAR10(root=root_path, train=True, download=True, transform=transform)\n",
    "    test_dataset = CIFAR10(root=root_path, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    print(\"Loaded CIFAR10 datasets with batch size\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, vgg16\n",
    "\n",
    "class EcgClient(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EcgClient, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, 7, padding=3)  # 128 x 16\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 64 x 16\n",
    "        self.conv2 = nn.Conv1d(16, 16, 5, padding=2)  # 64 x 16\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(2)  # 32 x 16\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 32 * 16)\n",
    "        return x\n",
    "class VGG16_Any_Cut_Client(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.cut_layer = config[\"cut_layer\"]\n",
    "\n",
    "        self.model = vgg16(weights=None)\n",
    "\n",
    "        features = list(self.model.features.children())\n",
    "        classifier = list(self.model.classifier.children())\n",
    "        self.model = nn.Sequential(*(features + classifier))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.model):\n",
    "            if i > self.cut_layer:\n",
    "                break\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "class AlexNetClient(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNetClient, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "class Resnet18_Any_Cut_Client(nn.Module): # M\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.cut_layer = config[\"cut_layer\"]\n",
    "\n",
    "        self.model = resnet18(weights = None)\n",
    "\n",
    "        self.model = nn.ModuleList(self.model.children())\n",
    "        self.model = nn.Sequential(*self.model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.model):\n",
    "            if i > self.cut_layer:\n",
    "                break\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "torch.cuda.get_device_name(0)\n",
    "assert('cuda' in device.type)\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "cut_layer = 3\n",
    "logits = 10\n",
    "\n",
    "config = {\"cut_layer\":cut_layer, \"logits\":logits}\n",
    "ecg_client = AlexNetClient()\n",
    "ecg_client.to(device)\n",
    "\n",
    "# checkpoint = torch.load(f\"../ecg_2conv/init_weight{mode}.pth\")\n",
    "# ecg_client.conv1.weight.data = checkpoint[\"conv1.weight\"]\n",
    "# ecg_client.conv1.bias.data = checkpoint[\"conv1.bias\"]\n",
    "# ecg_client.conv2.weight.data = checkpoint[\"conv2.weight\"]\n",
    "# ecg_client.conv2.bias.data = checkpoint[\"conv2.bias\"]\n",
    "epoch = 400\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001\n",
    "optimizer = Adam(ecg_client.parameters(), lr=lr)\n",
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = struct.pack('>I', len(msg)) + msg\n",
    "    sock.sendall(msg)\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    return recvall(sock, msglen)\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data\n",
    "host = 'localhost'\n",
    "port = 10080\n",
    "max_recv = 4096\n",
    "s = socket.socket()\n",
    "s.connect((host, port))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:15, 101.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.6747, acc: 35.32% / test_loss: 0.2795, test_acc: 48.48%\n",
      "Epoch 2 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 106.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.2900, acc: 53.77% / test_loss: 0.2339, test_acc: 58.39%\n",
      "Epoch 3 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 107.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.1324, acc: 60.20% / test_loss: 0.2249, test_acc: 61.40%\n",
      "Epoch 4 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 106.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0315, acc: 63.73% / test_loss: 0.2235, test_acc: 62.51%\n",
      "Epoch 5 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 106.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9661, acc: 66.24% / test_loss: 0.2242, test_acc: 63.38%\n",
      "Epoch 6 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 106.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9013, acc: 68.68% / test_loss: 0.2295, test_acc: 63.76%\n",
      "Epoch 7 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 106.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8553, acc: 70.39% / test_loss: 0.2117, test_acc: 64.76%\n",
      "Epoch 8 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 106.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8076, acc: 71.95% / test_loss: 0.2191, test_acc: 65.45%\n",
      "Epoch 9 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 106.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7699, acc: 73.43% / test_loss: 0.2259, test_acc: 65.35%\n",
      "Epoch 10 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 106.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7487, acc: 74.09% / test_loss: 0.2201, test_acc: 66.64%\n",
      "Epoch 11 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 106.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7088, acc: 75.83% / test_loss: 0.2283, test_acc: 66.27%\n",
      "Epoch 12 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 106.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6851, acc: 76.29% / test_loss: 0.2405, test_acc: 66.48%\n",
      "Epoch 13 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 107.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6550, acc: 77.57% / test_loss: 0.2363, test_acc: 66.90%\n",
      "Epoch 14 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 106.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6220, acc: 78.60% / test_loss: 0.2327, test_acc: 67.34%\n",
      "Epoch 15 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 107.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5927, acc: 79.85% / test_loss: 0.2513, test_acc: 67.18%\n",
      "Epoch 16 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 106.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5683, acc: 80.68% / test_loss: 0.2561, test_acc: 66.88%\n",
      "Epoch 17 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 107.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5517, acc: 81.27% / test_loss: 0.2553, test_acc: 66.66%\n",
      "Epoch 18 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 107.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5268, acc: 82.22% / test_loss: 0.2757, test_acc: 65.62%\n",
      "Epoch 19 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 107.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5181, acc: 82.63% / test_loss: 0.2778, test_acc: 66.59%\n",
      "Epoch 20 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 107.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4978, acc: 83.29% / test_loss: 0.2767, test_acc: 67.57%\n",
      "Epoch 21 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 107.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4918, acc: 83.82% / test_loss: 0.2823, test_acc: 67.79%\n",
      "Epoch 22 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 107.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4601, acc: 84.77% / test_loss: 0.2937, test_acc: 66.61%\n",
      "Epoch 23 - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:14, 105.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m x, label \u001b[39m=\u001b[39m batch\n\u001b[0;32m     27\u001b[0m x, label \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device), label\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 28\u001b[0m client_output \u001b[39m=\u001b[39m ecg_client(x)\n\u001b[0;32m     29\u001b[0m msg \u001b[39m=\u001b[39m {\n\u001b[0;32m     30\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mclient_output\u001b[39m\u001b[39m'\u001b[39m: client_output,\n\u001b[0;32m     31\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m: label\n\u001b[0;32m     32\u001b[0m }\n\u001b[0;32m     33\u001b[0m msg \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(msg)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[7], line 61\u001b[0m, in \u001b[0;36mAlexNetClient.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 61\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[0;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for e in range(epoch):\n",
    "    print(\"Epoch {} - \".format(e+1), end='')\n",
    "    \n",
    "    for _, batch in tqdm(enumerate(train_loader)):\n",
    "        x, label = batch\n",
    "        x, label = x.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        ecg_client = ecg_client.to(device)\n",
    "        output = ecg_client(x)\n",
    "        client_output = output.clone().detach().requires_grad_(True)\n",
    "        msg = {\n",
    "            'client_output': client_output,\n",
    "            'label': label\n",
    "        }\n",
    "        msg = pickle.dumps(msg)\n",
    "        send_msg(s, msg)\n",
    "        msg = recv_msg(s)\n",
    "        client_grad = pickle.loads(msg)\n",
    "        output.backward(client_grad)\n",
    "        optimizer.step()\n",
    "\n",
    "    # calculate test accuracy\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(test_loader):\n",
    "            x, label = batch\n",
    "            x, label = x.to(device), label.to(device)\n",
    "            client_output = ecg_client(x)\n",
    "            msg = {\n",
    "                'client_output': client_output,\n",
    "                'label': label\n",
    "            }\n",
    "            msg = pickle.dumps(msg)\n",
    "            send_msg(s, msg)\n",
    "    \n",
    "    msg = recv_msg(s)\n",
    "    train_test_status = pickle.loads(msg)\n",
    "    print(train_test_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training!\n",
      "Result is on the server side.\n"
     ]
    }
   ],
   "source": [
    "print('Finished Training!')\n",
    "print('Result is on the server side.')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

03-04 15:44 INFO     cuda
03-04 15:44 INFO     Command Line Arguments: 
{
    "epochs": 1,
    "comm_round": 10,
    "sample_fraction": 1.0,
    "alpha": 0.01,
    "dataset": "cifar10",
    "datadir": "../data/",
    "partition": "iid",
    "alg": "sflv2",
    "model": "resnet-18",
    "n_parties": 5,
    "lr": 0.001,
    "mu": 1,
    "std_coeff": 2.5,
    "unif_coeff": 0.5,
    "batch_size": 128,
    "load_first_net": 1,
    "pool_option": "FIFO",
    "model_buffer_size": 1,
    "optimizer": "adam",
    "simp_width": 1,
    "out_dim": 256,
    "reg": 0.0005,
    "temperature": 0.5,
    "logdir": "./",
    "log_file_name": "logs/experiment_log-alg=sflv2_partition=iid_lr=0.001_epochs=1_num_users=5_beta=0.01_batch_size=128_opt=adam_dataset=cifar10_2024-03-04-1544-09",
    "seed": 42,
    "device": "cuda",
    "multiprocessing": 0
}
03-04 15:44 INFO     Data statistics: {0: {0: 973, 1: 979, 2: 1030, 3: 1023, 4: 933, 5: 1015, 6: 996, 7: 994, 8: 1017, 9: 1040}, 1: {0: 1000, 1: 1000, 2: 979, 3: 1018, 4: 1011, 5: 1018, 6: 944, 7: 999, 8: 1028, 9: 1003}, 2: {0: 981, 1: 1048, 2: 1007, 3: 991, 4: 999, 5: 998, 6: 1026, 7: 986, 8: 968, 9: 996}, 3: {0: 1036, 1: 984, 2: 991, 3: 1001, 4: 1046, 5: 965, 6: 1001, 7: 975, 8: 983, 9: 1018}, 4: {0: 1010, 1: 989, 2: 993, 3: 967, 4: 1011, 5: 1004, 6: 1033, 7: 1046, 8: 1004, 9: 943}}
03-04 15:44 INFO     in comm round:0
03-04 15:44 INFO     Training network 0 n_training: 10000
03-04 15:44 INFO     Training network 0
03-04 15:44 INFO     n_training: 78
03-04 15:44 INFO     Client: 0 Epoch: 0 Loss: 1.7657077679267297
03-04 15:44 INFO      ** Client: 0 Training complete **
03-04 15:44 INFO     Training network 1 n_training: 10000
03-04 15:44 INFO     Training network 1
03-04 15:44 INFO     n_training: 78
03-04 15:44 INFO     Client: 1 Epoch: 0 Loss: 1.823494668190296
03-04 15:44 INFO      ** Client: 1 Training complete **
03-04 15:44 INFO     Training network 2 n_training: 10000
03-04 15:44 INFO     Training network 2
03-04 15:44 INFO     n_training: 78
03-04 15:44 INFO     Client: 2 Epoch: 0 Loss: 1.806031360076024
03-04 15:44 INFO      ** Client: 2 Training complete **
03-04 15:44 INFO     Training network 3 n_training: 10000
03-04 15:44 INFO     Training network 3
03-04 15:44 INFO     n_training: 78
03-04 15:44 INFO     Client: 3 Epoch: 0 Loss: 1.8374965404852843
03-04 15:44 INFO      ** Client: 3 Training complete **
03-04 15:44 INFO     Training network 4 n_training: 10000
03-04 15:44 INFO     Training network 4
03-04 15:44 INFO     n_training: 78
03-04 15:44 INFO     Client: 4 Epoch: 0 Loss: 1.7833841213813195
03-04 15:44 INFO      ** Client: 4 Training complete **
03-04 15:44 INFO     global n_training: 390
03-04 15:44 INFO     global n_test: 79
03-04 15:44 INFO     >> Global Model Train accuracy: 0.113442
03-04 15:44 INFO     >> Global Model Test accuracy: 0.114000
03-04 15:44 INFO     >> Global Model Train loss: 2.562739
03-04 15:44 INFO     in comm round:1
03-04 15:44 INFO     Training network 0 n_training: 10000
03-04 15:44 INFO     Training network 0
03-04 15:44 INFO     n_training: 78
03-04 15:44 INFO     Client: 0 Epoch: 0 Loss: 1.6390253794498932
03-04 15:44 INFO      ** Client: 0 Training complete **
03-04 15:44 INFO     Training network 1 n_training: 10000
03-04 15:44 INFO     Training network 1
03-04 15:44 INFO     n_training: 78
03-04 15:44 INFO     Client: 1 Epoch: 0 Loss: 1.6067114655788128
03-04 15:44 INFO      ** Client: 1 Training complete **
03-04 15:44 INFO     Training network 2 n_training: 10000
03-04 15:44 INFO     Training network 2
03-04 15:44 INFO     n_training: 78
03-04 15:44 INFO     Client: 2 Epoch: 0 Loss: 1.6166576911241581
03-04 15:44 INFO      ** Client: 2 Training complete **
03-04 15:44 INFO     Training network 3 n_training: 10000
03-04 15:44 INFO     Training network 3
03-04 15:44 INFO     n_training: 78
03-04 15:45 INFO     Client: 3 Epoch: 0 Loss: 1.6426362899633555
03-04 15:45 INFO      ** Client: 3 Training complete **
03-04 15:45 INFO     Training network 4 n_training: 10000
03-04 15:45 INFO     Training network 4
03-04 15:45 INFO     n_training: 78
03-04 15:45 INFO     Client: 4 Epoch: 0 Loss: 1.69207508288897
03-04 15:45 INFO      ** Client: 4 Training complete **
03-04 15:45 INFO     global n_training: 390
03-04 15:45 INFO     global n_test: 79
03-04 15:45 INFO     >> Global Model Train accuracy: 0.250982
03-04 15:45 INFO     >> Global Model Test accuracy: 0.253200
03-04 15:45 INFO     >> Global Model Train loss: 1.971274
03-04 15:45 INFO     in comm round:2
03-04 15:45 INFO     Training network 0 n_training: 10000
03-04 15:45 INFO     Training network 0
03-04 15:45 INFO     n_training: 78
03-04 15:45 INFO     Client: 0 Epoch: 0 Loss: 1.44812644750644
03-04 15:45 INFO      ** Client: 0 Training complete **
03-04 15:45 INFO     Training network 1 n_training: 10000
03-04 15:45 INFO     Training network 1
03-04 15:45 INFO     n_training: 78
03-04 15:45 INFO     Client: 1 Epoch: 0 Loss: 1.447142474162273
03-04 15:45 INFO      ** Client: 1 Training complete **
03-04 15:45 INFO     Training network 2 n_training: 10000
03-04 15:45 INFO     Training network 2
03-04 15:45 INFO     n_training: 78
03-04 15:45 INFO     Client: 2 Epoch: 0 Loss: 1.4211563177597828
03-04 15:45 INFO      ** Client: 2 Training complete **
03-04 15:45 INFO     Training network 3 n_training: 10000
03-04 15:45 INFO     Training network 3
03-04 15:45 INFO     n_training: 78
03-04 15:45 INFO     Client: 3 Epoch: 0 Loss: 1.4657358022836537
03-04 15:45 INFO      ** Client: 3 Training complete **
03-04 15:45 INFO     Training network 4 n_training: 10000
03-04 15:45 INFO     Training network 4
03-04 15:45 INFO     n_training: 78
03-04 15:45 INFO     Client: 4 Epoch: 0 Loss: 1.4474837963397686
03-04 15:45 INFO      ** Client: 4 Training complete **
03-04 15:45 INFO     global n_training: 390
03-04 15:45 INFO     global n_test: 79
03-04 15:45 INFO     >> Global Model Train accuracy: 0.541086
03-04 15:45 INFO     >> Global Model Test accuracy: 0.538300
03-04 15:45 INFO     >> Global Model Train loss: 1.274899
03-04 15:45 INFO     in comm round:3
03-04 15:45 INFO     Training network 0 n_training: 10000
03-04 15:45 INFO     Training network 0
03-04 15:45 INFO     n_training: 78
03-04 15:45 INFO     Client: 0 Epoch: 0 Loss: 1.2643646200497944
03-04 15:45 INFO      ** Client: 0 Training complete **
03-04 15:45 INFO     Training network 1 n_training: 10000
03-04 15:45 INFO     Training network 1
03-04 15:45 INFO     n_training: 78
03-04 15:45 INFO     Client: 1 Epoch: 0 Loss: 1.2925809637094154
03-04 15:45 INFO      ** Client: 1 Training complete **
03-04 15:45 INFO     Training network 2 n_training: 10000
03-04 15:45 INFO     Training network 2
03-04 15:45 INFO     n_training: 78
03-04 15:45 INFO     Client: 2 Epoch: 0 Loss: 1.2727670318041093
03-04 15:45 INFO      ** Client: 2 Training complete **
03-04 15:45 INFO     Training network 3 n_training: 10000
03-04 15:45 INFO     Training network 3
03-04 15:45 INFO     n_training: 78
03-04 15:45 INFO     Client: 3 Epoch: 0 Loss: 1.2751626326487615
03-04 15:45 INFO      ** Client: 3 Training complete **
03-04 15:45 INFO     Training network 4 n_training: 10000
03-04 15:45 INFO     Training network 4
03-04 15:45 INFO     n_training: 78
03-04 15:45 INFO     Client: 4 Epoch: 0 Loss: 1.2753726366238716
03-04 15:45 INFO      ** Client: 4 Training complete **
03-04 15:45 INFO     global n_training: 390
03-04 15:45 INFO     global n_test: 79
03-04 15:45 INFO     >> Global Model Train accuracy: 0.599559
03-04 15:45 INFO     >> Global Model Test accuracy: 0.590500
03-04 15:45 INFO     >> Global Model Train loss: 1.109096
03-04 15:45 INFO     in comm round:4
03-04 15:45 INFO     Training network 0 n_training: 10000
03-04 15:45 INFO     Training network 0
03-04 15:45 INFO     n_training: 78
03-04 15:46 INFO     Client: 0 Epoch: 0 Loss: 1.1132493515809376
03-04 15:46 INFO      ** Client: 0 Training complete **
03-04 15:46 INFO     Training network 1 n_training: 10000
03-04 15:46 INFO     Training network 1
03-04 15:46 INFO     n_training: 78
03-04 15:46 INFO     Client: 1 Epoch: 0 Loss: 1.119318398145529
03-04 15:46 INFO      ** Client: 1 Training complete **
03-04 15:46 INFO     Training network 2 n_training: 10000
03-04 15:46 INFO     Training network 2
03-04 15:46 INFO     n_training: 78
03-04 15:46 INFO     Client: 2 Epoch: 0 Loss: 1.131804074232395
03-04 15:46 INFO      ** Client: 2 Training complete **
03-04 15:46 INFO     Training network 3 n_training: 10000
03-04 15:46 INFO     Training network 3
03-04 15:46 INFO     n_training: 78
03-04 15:46 INFO     Client: 3 Epoch: 0 Loss: 1.1170117801580675
03-04 15:46 INFO      ** Client: 3 Training complete **
03-04 15:46 INFO     Training network 4 n_training: 10000
03-04 15:46 INFO     Training network 4
03-04 15:46 INFO     n_training: 78
03-04 15:46 INFO     Client: 4 Epoch: 0 Loss: 1.1155596360182152
03-04 15:46 INFO      ** Client: 4 Training complete **
03-04 15:46 INFO     global n_training: 390
03-04 15:46 INFO     global n_test: 79
03-04 15:46 INFO     >> Global Model Train accuracy: 0.666146
03-04 15:46 INFO     >> Global Model Test accuracy: 0.657100
03-04 15:46 INFO     >> Global Model Train loss: 0.945370
03-04 15:46 INFO     in comm round:5
03-04 15:46 INFO     Training network 0 n_training: 10000
03-04 15:46 INFO     Training network 0
03-04 15:46 INFO     n_training: 78
03-04 15:46 INFO     Client: 0 Epoch: 0 Loss: 0.9902678903860923
03-04 15:46 INFO      ** Client: 0 Training complete **
03-04 15:46 INFO     Training network 1 n_training: 10000
03-04 15:46 INFO     Training network 1
03-04 15:46 INFO     n_training: 78
03-04 15:46 INFO     Client: 1 Epoch: 0 Loss: 0.999454772625214
03-04 15:46 INFO      ** Client: 1 Training complete **
03-04 15:46 INFO     Training network 2 n_training: 10000
03-04 15:46 INFO     Training network 2
03-04 15:46 INFO     n_training: 78
03-04 15:46 INFO     Client: 2 Epoch: 0 Loss: 0.991476690922028
03-04 15:46 INFO      ** Client: 2 Training complete **
03-04 15:46 INFO     Training network 3 n_training: 10000
03-04 15:46 INFO     Training network 3
03-04 15:46 INFO     n_training: 78
03-04 15:46 INFO     Client: 3 Epoch: 0 Loss: 0.9873951925681188
03-04 15:46 INFO      ** Client: 3 Training complete **
03-04 15:46 INFO     Training network 4 n_training: 10000
03-04 15:46 INFO     Training network 4
03-04 15:46 INFO     n_training: 78
03-04 15:46 INFO     Client: 4 Epoch: 0 Loss: 0.9837800906254694
03-04 15:46 INFO      ** Client: 4 Training complete **
03-04 15:46 INFO     global n_training: 390
03-04 15:46 INFO     global n_test: 79
03-04 15:46 INFO     >> Global Model Train accuracy: 0.707792
03-04 15:46 INFO     >> Global Model Test accuracy: 0.695300
03-04 15:46 INFO     >> Global Model Train loss: 0.830358
03-04 15:46 INFO     in comm round:6
03-04 15:46 INFO     Training network 0 n_training: 10000
03-04 15:46 INFO     Training network 0
03-04 15:46 INFO     n_training: 78
03-04 15:46 INFO     Client: 0 Epoch: 0 Loss: 0.871265749900769
03-04 15:46 INFO      ** Client: 0 Training complete **
03-04 15:46 INFO     Training network 1 n_training: 10000
03-04 15:46 INFO     Training network 1
03-04 15:46 INFO     n_training: 78
03-04 15:46 INFO     Client: 1 Epoch: 0 Loss: 0.8749354069049542
03-04 15:46 INFO      ** Client: 1 Training complete **
03-04 15:46 INFO     Training network 2 n_training: 10000
03-04 15:46 INFO     Training network 2
03-04 15:46 INFO     n_training: 78
03-04 15:46 INFO     Client: 2 Epoch: 0 Loss: 0.8763201053325946
03-04 15:46 INFO      ** Client: 2 Training complete **
03-04 15:46 INFO     Training network 3 n_training: 10000
03-04 15:46 INFO     Training network 3
03-04 15:46 INFO     n_training: 78
03-04 15:46 INFO     Client: 3 Epoch: 0 Loss: 0.8678644108466613
03-04 15:46 INFO      ** Client: 3 Training complete **
03-04 15:46 INFO     Training network 4 n_training: 10000
03-04 15:46 INFO     Training network 4
03-04 15:46 INFO     n_training: 78
03-04 15:47 INFO     Client: 4 Epoch: 0 Loss: 0.8622237268166665
03-04 15:47 INFO      ** Client: 4 Training complete **
03-04 15:47 INFO     global n_training: 390
03-04 15:47 INFO     global n_test: 79
03-04 15:47 INFO     >> Global Model Train accuracy: 0.740405
03-04 15:47 INFO     >> Global Model Test accuracy: 0.725800
03-04 15:47 INFO     >> Global Model Train loss: 0.739884
03-04 15:47 INFO     in comm round:7
03-04 15:47 INFO     Training network 0 n_training: 10000
03-04 15:47 INFO     Training network 0
03-04 15:47 INFO     n_training: 78
03-04 15:47 INFO     Client: 0 Epoch: 0 Loss: 0.7623900343210269
03-04 15:47 INFO      ** Client: 0 Training complete **
03-04 15:47 INFO     Training network 1 n_training: 10000
03-04 15:47 INFO     Training network 1
03-04 15:47 INFO     n_training: 78
03-04 15:47 INFO     Client: 1 Epoch: 0 Loss: 0.7757682899634043
03-04 15:47 INFO      ** Client: 1 Training complete **
03-04 15:47 INFO     Training network 2 n_training: 10000
03-04 15:47 INFO     Training network 2
03-04 15:47 INFO     n_training: 78
03-04 15:47 INFO     Client: 2 Epoch: 0 Loss: 0.7824606734972733
03-04 15:47 INFO      ** Client: 2 Training complete **
03-04 15:47 INFO     Training network 3 n_training: 10000
03-04 15:47 INFO     Training network 3
03-04 15:47 INFO     n_training: 78
03-04 15:47 INFO     Client: 3 Epoch: 0 Loss: 0.7551509180130103
03-04 15:47 INFO      ** Client: 3 Training complete **
03-04 15:47 INFO     Training network 4 n_training: 10000
03-04 15:47 INFO     Training network 4
03-04 15:47 INFO     n_training: 78
03-04 15:47 INFO     Client: 4 Epoch: 0 Loss: 0.7588330874076257
03-04 15:47 INFO      ** Client: 4 Training complete **
03-04 15:47 INFO     global n_training: 390
03-04 15:47 INFO     global n_test: 79
03-04 15:47 INFO     >> Global Model Train accuracy: 0.767188
03-04 15:47 INFO     >> Global Model Test accuracy: 0.742900
03-04 15:47 INFO     >> Global Model Train loss: 0.663147
03-04 15:47 INFO     in comm round:8
03-04 15:47 INFO     Training network 0 n_training: 10000
03-04 15:47 INFO     Training network 0
03-04 15:47 INFO     n_training: 78
03-04 15:47 INFO     Client: 0 Epoch: 0 Loss: 0.6746605642330952
03-04 15:47 INFO      ** Client: 0 Training complete **
03-04 15:47 INFO     Training network 1 n_training: 10000
03-04 15:47 INFO     Training network 1
03-04 15:47 INFO     n_training: 78
03-04 15:47 INFO     Client: 1 Epoch: 0 Loss: 0.6935015679934086
03-04 15:47 INFO      ** Client: 1 Training complete **
03-04 15:47 INFO     Training network 2 n_training: 10000
03-04 15:47 INFO     Training network 2
03-04 15:47 INFO     n_training: 78
03-04 15:47 INFO     Client: 2 Epoch: 0 Loss: 0.6872476713779645
03-04 15:47 INFO      ** Client: 2 Training complete **
03-04 15:47 INFO     Training network 3 n_training: 10000
03-04 15:47 INFO     Training network 3
03-04 15:47 INFO     n_training: 78
03-04 15:47 INFO     Client: 3 Epoch: 0 Loss: 0.6709874646785932
03-04 15:47 INFO      ** Client: 3 Training complete **
03-04 15:47 INFO     Training network 4 n_training: 10000
03-04 15:47 INFO     Training network 4
03-04 15:47 INFO     n_training: 78
03-04 15:47 INFO     Client: 4 Epoch: 0 Loss: 0.6675881537107321
03-04 15:47 INFO      ** Client: 4 Training complete **
03-04 15:47 INFO     global n_training: 390
03-04 15:47 INFO     global n_test: 79
03-04 15:47 INFO     >> Global Model Train accuracy: 0.785397
03-04 15:47 INFO     >> Global Model Test accuracy: 0.754500
03-04 15:47 INFO     >> Global Model Train loss: 0.610956
03-04 15:47 INFO     in comm round:9
03-04 15:47 INFO     Training network 0 n_training: 10000
03-04 15:47 INFO     Training network 0
03-04 15:47 INFO     n_training: 78
03-04 15:47 INFO     Client: 0 Epoch: 0 Loss: 0.6217890710402758
03-04 15:47 INFO      ** Client: 0 Training complete **
03-04 15:47 INFO     Training network 1 n_training: 10000
03-04 15:47 INFO     Training network 1
03-04 15:47 INFO     n_training: 78
03-04 15:47 INFO     Client: 1 Epoch: 0 Loss: 0.6293168977285043
03-04 15:47 INFO      ** Client: 1 Training complete **
03-04 15:47 INFO     Training network 2 n_training: 10000
03-04 15:47 INFO     Training network 2
03-04 15:47 INFO     n_training: 78
03-04 15:48 INFO     Client: 2 Epoch: 0 Loss: 0.6328657567501068
03-04 15:48 INFO      ** Client: 2 Training complete **
03-04 15:48 INFO     Training network 3 n_training: 10000
03-04 15:48 INFO     Training network 3
03-04 15:48 INFO     n_training: 78
03-04 15:48 INFO     Client: 3 Epoch: 0 Loss: 0.6109242893946476
03-04 15:48 INFO      ** Client: 3 Training complete **
03-04 15:48 INFO     Training network 4 n_training: 10000
03-04 15:48 INFO     Training network 4
03-04 15:48 INFO     n_training: 78
03-04 15:48 INFO     Client: 4 Epoch: 0 Loss: 0.6098324320255182
03-04 15:48 INFO      ** Client: 4 Training complete **
03-04 15:48 INFO     global n_training: 390
03-04 15:48 INFO     global n_test: 79
03-04 15:48 INFO     >> Global Model Train accuracy: 0.792608
03-04 15:48 INFO     >> Global Model Test accuracy: 0.759300
03-04 15:48 INFO     >> Global Model Train loss: 0.589441

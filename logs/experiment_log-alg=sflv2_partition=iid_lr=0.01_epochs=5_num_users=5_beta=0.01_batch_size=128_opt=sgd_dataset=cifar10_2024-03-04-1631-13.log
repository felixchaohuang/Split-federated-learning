03-04 16:31 INFO     cuda
03-04 16:31 INFO     Command Line Arguments: 
{
    "epochs": 5,
    "comm_round": 100,
    "sample_fraction": 1.0,
    "alpha": 0.01,
    "dataset": "cifar10",
    "datadir": "../data/",
    "partition": "iid",
    "alg": "sflv2",
    "model": "resnet-18",
    "n_parties": 5,
    "lr": 0.01,
    "mu": 1,
    "std_coeff": 2.5,
    "unif_coeff": 0.5,
    "batch_size": 128,
    "load_first_net": 1,
    "pool_option": "FIFO",
    "model_buffer_size": 1,
    "optimizer": "sgd",
    "simp_width": 1,
    "out_dim": 256,
    "reg": 0.0005,
    "temperature": 0.5,
    "logdir": "./",
    "log_file_name": "logs/experiment_log-alg=sflv2_partition=iid_lr=0.01_epochs=5_num_users=5_beta=0.01_batch_size=128_opt=sgd_dataset=cifar10_2024-03-04-1631-13",
    "seed": 42,
    "device": "cuda",
    "multiprocessing": 0
}
03-04 16:31 INFO     Data statistics: {0: {0: 973, 1: 979, 2: 1030, 3: 1023, 4: 933, 5: 1015, 6: 996, 7: 994, 8: 1017, 9: 1040}, 1: {0: 1000, 1: 1000, 2: 979, 3: 1018, 4: 1011, 5: 1018, 6: 944, 7: 999, 8: 1028, 9: 1003}, 2: {0: 981, 1: 1048, 2: 1007, 3: 991, 4: 999, 5: 998, 6: 1026, 7: 986, 8: 968, 9: 996}, 3: {0: 1036, 1: 984, 2: 991, 3: 1001, 4: 1046, 5: 965, 6: 1001, 7: 975, 8: 983, 9: 1018}, 4: {0: 1010, 1: 989, 2: 993, 3: 967, 4: 1011, 5: 1004, 6: 1033, 7: 1046, 8: 1004, 9: 943}}
03-04 16:31 INFO     in comm round:0
03-04 16:31 INFO     Training network 0 n_training: 10000
03-04 16:31 INFO     Training network 0
03-04 16:31 INFO     n_training: 78
03-04 16:31 INFO     Client: 0 Epoch: 0 Loss: 1.74853958380528
03-04 16:31 INFO     Client: 0 Epoch: 1 Loss: 1.3337892309213295
03-04 16:31 INFO     Client: 0 Epoch: 2 Loss: 1.0609439000105247
03-04 16:31 INFO     Client: 0 Epoch: 3 Loss: 0.8351204097270966
03-04 16:31 INFO     Client: 0 Epoch: 4 Loss: 0.5803230695235424
03-04 16:31 INFO      ** Client: 0 Training complete **
03-04 16:31 INFO     Training network 1 n_training: 10000
03-04 16:31 INFO     Training network 1
03-04 16:31 INFO     n_training: 78
03-04 16:31 INFO     Client: 1 Epoch: 0 Loss: 1.724506384287125
03-04 16:31 INFO     Client: 1 Epoch: 1 Loss: 1.2975538021478898
03-04 16:31 INFO     Client: 1 Epoch: 2 Loss: 1.04366980607693
03-04 16:31 INFO     Client: 1 Epoch: 3 Loss: 0.7777377206545609
03-04 16:31 INFO     Client: 1 Epoch: 4 Loss: 0.50753697905785
03-04 16:31 INFO      ** Client: 1 Training complete **
03-04 16:31 INFO     Training network 2 n_training: 10000
03-04 16:31 INFO     Training network 2
03-04 16:31 INFO     n_training: 78
03-04 16:31 INFO     Client: 2 Epoch: 0 Loss: 1.7422578946138039
03-04 16:31 INFO     Client: 2 Epoch: 1 Loss: 1.3182472173984234
03-04 16:32 INFO     Client: 2 Epoch: 2 Loss: 1.0806150742066212
03-04 16:32 INFO     Client: 2 Epoch: 3 Loss: 0.8349807346478487
03-04 16:32 INFO     Client: 2 Epoch: 4 Loss: 0.5896716499939944
03-04 16:32 INFO      ** Client: 2 Training complete **
03-04 16:32 INFO     Training network 3 n_training: 10000
03-04 16:32 INFO     Training network 3
03-04 16:32 INFO     n_training: 78
03-04 16:32 INFO     Client: 3 Epoch: 0 Loss: 1.7246087147639348
03-04 16:32 INFO     Client: 3 Epoch: 1 Loss: 1.2708546771452978
03-04 16:32 INFO     Client: 3 Epoch: 2 Loss: 1.005326122045517
03-04 16:32 INFO     Client: 3 Epoch: 3 Loss: 0.7636294769935119
03-04 16:32 INFO     Client: 3 Epoch: 4 Loss: 0.4969716106469815
03-04 16:32 INFO      ** Client: 3 Training complete **
03-04 16:32 INFO     Training network 4 n_training: 10000
03-04 16:32 INFO     Training network 4
03-04 16:32 INFO     n_training: 78
03-04 16:32 INFO     Client: 4 Epoch: 0 Loss: 1.7407417312646523
03-04 16:32 INFO     Client: 4 Epoch: 1 Loss: 1.279729840083
03-04 16:32 INFO     Client: 4 Epoch: 2 Loss: 1.0335279756631606
03-04 16:32 INFO     Client: 4 Epoch: 3 Loss: 0.7911189458309076
03-04 16:32 INFO     Client: 4 Epoch: 4 Loss: 0.5371580647352414
03-04 16:32 INFO      ** Client: 4 Training complete **
03-04 16:32 INFO     global n_training: 390
03-04 16:32 INFO     global n_test: 79
03-04 16:32 INFO     >> Global Model Train accuracy: 0.166426
03-04 16:32 INFO     >> Global Model Test accuracy: 0.167400
03-04 16:32 INFO     >> Global Model Train loss: 3.981462
03-04 16:32 INFO     in comm round:1
03-04 16:32 INFO     Training network 0 n_training: 10000
03-04 16:32 INFO     Training network 0
03-04 16:32 INFO     n_training: 78
03-04 16:32 INFO     Client: 0 Epoch: 0 Loss: 1.1555290871705763

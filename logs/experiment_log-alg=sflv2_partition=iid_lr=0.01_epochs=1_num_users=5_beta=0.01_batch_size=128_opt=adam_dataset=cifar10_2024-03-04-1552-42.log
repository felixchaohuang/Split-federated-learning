03-04 15:52 INFO     cuda
03-04 15:52 INFO     Command Line Arguments: 
{
    "epochs": 1,
    "comm_round": 10,
    "sample_fraction": 1.0,
    "alpha": 0.01,
    "dataset": "cifar10",
    "datadir": "../data/",
    "partition": "iid",
    "alg": "sflv2",
    "model": "resnet-18",
    "n_parties": 5,
    "lr": 0.01,
    "mu": 1,
    "std_coeff": 2.5,
    "unif_coeff": 0.5,
    "batch_size": 128,
    "load_first_net": 1,
    "pool_option": "FIFO",
    "model_buffer_size": 1,
    "optimizer": "adam",
    "simp_width": 1,
    "out_dim": 256,
    "reg": 0.0005,
    "temperature": 0.5,
    "logdir": "./",
    "log_file_name": "logs/experiment_log-alg=sflv2_partition=iid_lr=0.01_epochs=1_num_users=5_beta=0.01_batch_size=128_opt=adam_dataset=cifar10_2024-03-04-1552-42",
    "seed": 42,
    "device": "cuda",
    "multiprocessing": 0
}
03-04 15:52 INFO     Data statistics: {0: {0: 973, 1: 979, 2: 1030, 3: 1023, 4: 933, 5: 1015, 6: 996, 7: 994, 8: 1017, 9: 1040}, 1: {0: 1000, 1: 1000, 2: 979, 3: 1018, 4: 1011, 5: 1018, 6: 944, 7: 999, 8: 1028, 9: 1003}, 2: {0: 981, 1: 1048, 2: 1007, 3: 991, 4: 999, 5: 998, 6: 1026, 7: 986, 8: 968, 9: 996}, 3: {0: 1036, 1: 984, 2: 991, 3: 1001, 4: 1046, 5: 965, 6: 1001, 7: 975, 8: 983, 9: 1018}, 4: {0: 1010, 1: 989, 2: 993, 3: 967, 4: 1011, 5: 1004, 6: 1033, 7: 1046, 8: 1004, 9: 943}}
03-04 15:52 INFO     in comm round:0
03-04 15:52 INFO     Training network 0 n_training: 10000
03-04 15:52 INFO     Training network 0
03-04 15:52 INFO     n_training: 78
03-04 15:52 INFO     Client: 0 Epoch: 0 Loss: 2.0078251850910678
03-04 15:52 INFO      ** Client: 0 Training complete **
03-04 15:52 INFO     Training network 1 n_training: 10000
03-04 15:52 INFO     Training network 1
03-04 15:52 INFO     n_training: 78
03-04 15:52 INFO     Client: 1 Epoch: 0 Loss: 2.021062288528834
03-04 15:52 INFO      ** Client: 1 Training complete **
03-04 15:52 INFO     Training network 2 n_training: 10000
03-04 15:52 INFO     Training network 2
03-04 15:52 INFO     n_training: 78
03-04 15:53 INFO     Client: 2 Epoch: 0 Loss: 1.9716369815361805
03-04 15:53 INFO      ** Client: 2 Training complete **
03-04 15:53 INFO     Training network 3 n_training: 10000
03-04 15:53 INFO     Training network 3
03-04 15:53 INFO     n_training: 78
03-04 15:53 INFO     Client: 3 Epoch: 0 Loss: 2.011363501732166
03-04 15:53 INFO      ** Client: 3 Training complete **
03-04 15:53 INFO     Training network 4 n_training: 10000
03-04 15:53 INFO     Training network 4
03-04 15:53 INFO     n_training: 78
03-04 15:53 INFO     Client: 4 Epoch: 0 Loss: 2.033574709525475
03-04 15:53 INFO      ** Client: 4 Training complete **
03-04 15:53 INFO     global n_training: 390
03-04 15:53 INFO     global n_test: 79
03-04 15:53 INFO     >> Global Model Train accuracy: 0.100000
03-04 15:53 INFO     >> Global Model Test accuracy: 0.100000
03-04 15:53 INFO     >> Global Model Train loss: 2.477743
03-04 15:53 INFO     in comm round:1
03-04 15:53 INFO     Training network 0 n_training: 10000
03-04 15:53 INFO     Training network 0
03-04 15:53 INFO     n_training: 78
03-04 15:53 INFO     Client: 0 Epoch: 0 Loss: 1.942071373646076
03-04 15:53 INFO      ** Client: 0 Training complete **
03-04 15:53 INFO     Training network 1 n_training: 10000
03-04 15:53 INFO     Training network 1
03-04 15:53 INFO     n_training: 78
03-04 15:53 INFO     Client: 1 Epoch: 0 Loss: 1.9085303820096529
03-04 15:53 INFO      ** Client: 1 Training complete **
03-04 15:53 INFO     Training network 2 n_training: 10000
03-04 15:53 INFO     Training network 2
03-04 15:53 INFO     n_training: 78
03-04 15:53 INFO     Client: 2 Epoch: 0 Loss: 1.8839007998124147
03-04 15:53 INFO      ** Client: 2 Training complete **
03-04 15:53 INFO     Training network 3 n_training: 10000
03-04 15:53 INFO     Training network 3
03-04 15:53 INFO     n_training: 78
03-04 15:53 INFO     Client: 3 Epoch: 0 Loss: 1.8990799203897133
03-04 15:53 INFO      ** Client: 3 Training complete **
03-04 15:53 INFO     Training network 4 n_training: 10000
03-04 15:53 INFO     Training network 4
03-04 15:53 INFO     n_training: 78
03-04 15:53 INFO     Client: 4 Epoch: 0 Loss: 1.8956268292206984
03-04 15:53 INFO      ** Client: 4 Training complete **
03-04 15:53 INFO     global n_training: 390
03-04 15:53 INFO     global n_test: 79
03-04 15:53 INFO     >> Global Model Train accuracy: 0.100060
03-04 15:53 INFO     >> Global Model Test accuracy: 0.100000
03-04 15:53 INFO     >> Global Model Train loss: 2.409616
03-04 15:53 INFO     in comm round:2
03-04 15:53 INFO     Training network 0 n_training: 10000
03-04 15:53 INFO     Training network 0
03-04 15:53 INFO     n_training: 78
03-04 15:53 INFO     Client: 0 Epoch: 0 Loss: 1.8731369651280916
03-04 15:53 INFO      ** Client: 0 Training complete **
03-04 15:53 INFO     Training network 1 n_training: 10000
03-04 15:53 INFO     Training network 1
03-04 15:53 INFO     n_training: 78
03-04 15:53 INFO     Client: 1 Epoch: 0 Loss: 1.8460390690045478
03-04 15:53 INFO      ** Client: 1 Training complete **
03-04 15:53 INFO     Training network 2 n_training: 10000
03-04 15:53 INFO     Training network 2
03-04 15:53 INFO     n_training: 78
03-04 15:53 INFO     Client: 2 Epoch: 0 Loss: 1.8721602039459424
03-04 15:53 INFO      ** Client: 2 Training complete **
03-04 15:53 INFO     Training network 3 n_training: 10000
03-04 15:53 INFO     Training network 3
03-04 15:53 INFO     n_training: 78
03-04 15:53 INFO     Client: 3 Epoch: 0 Loss: 1.9137864983998811
03-04 15:53 INFO      ** Client: 3 Training complete **
03-04 15:53 INFO     Training network 4 n_training: 10000
03-04 15:53 INFO     Training network 4
03-04 15:53 INFO     n_training: 78
03-04 15:53 INFO     Client: 4 Epoch: 0 Loss: 1.8296163464203858
03-04 15:53 INFO      ** Client: 4 Training complete **
03-04 15:53 INFO     global n_training: 390
03-04 15:53 INFO     global n_test: 79
03-04 15:54 INFO     >> Global Model Train accuracy: 0.100040
03-04 15:54 INFO     >> Global Model Test accuracy: 0.100000
03-04 15:54 INFO     >> Global Model Train loss: 2.373752
03-04 15:54 INFO     in comm round:3
03-04 15:54 INFO     Training network 0 n_training: 10000
03-04 15:54 INFO     Training network 0
03-04 15:54 INFO     n_training: 78
03-04 15:54 INFO     Client: 0 Epoch: 0 Loss: 1.8357295562059452
03-04 15:54 INFO      ** Client: 0 Training complete **
03-04 15:54 INFO     Training network 1 n_training: 10000
03-04 15:54 INFO     Training network 1
03-04 15:54 INFO     n_training: 78
03-04 15:54 INFO     Client: 1 Epoch: 0 Loss: 1.8680150417181163
03-04 15:54 INFO      ** Client: 1 Training complete **
03-04 15:54 INFO     Training network 2 n_training: 10000
03-04 15:54 INFO     Training network 2
03-04 15:54 INFO     n_training: 78
03-04 15:54 INFO     Client: 2 Epoch: 0 Loss: 1.8452715292955055
03-04 15:54 INFO      ** Client: 2 Training complete **
03-04 15:54 INFO     Training network 3 n_training: 10000
03-04 15:54 INFO     Training network 3
03-04 15:54 INFO     n_training: 78
03-04 15:54 INFO     Client: 3 Epoch: 0 Loss: 1.841679620437133
03-04 15:54 INFO      ** Client: 3 Training complete **
03-04 15:54 INFO     Training network 4 n_training: 10000
03-04 15:54 INFO     Training network 4
03-04 15:54 INFO     n_training: 78
03-04 15:54 INFO     Client: 4 Epoch: 0 Loss: 1.8927418895256825
03-04 15:54 INFO      ** Client: 4 Training complete **
03-04 15:54 INFO     global n_training: 390
03-04 15:54 INFO     global n_test: 79
03-04 15:54 INFO     >> Global Model Train accuracy: 0.100060
03-04 15:54 INFO     >> Global Model Test accuracy: 0.100000
03-04 15:54 INFO     >> Global Model Train loss: 2.421719
03-04 15:54 INFO     in comm round:4
03-04 15:54 INFO     Training network 0 n_training: 10000
03-04 15:54 INFO     Training network 0
03-04 15:54 INFO     n_training: 78
03-04 15:54 INFO     Client: 0 Epoch: 0 Loss: 1.8191655217072902
03-04 15:54 INFO      ** Client: 0 Training complete **
03-04 15:54 INFO     Training network 1 n_training: 10000
03-04 15:54 INFO     Training network 1
03-04 15:54 INFO     n_training: 78
03-04 15:54 INFO     Client: 1 Epoch: 0 Loss: 1.821924443428333
03-04 15:54 INFO      ** Client: 1 Training complete **
03-04 15:54 INFO     Training network 2 n_training: 10000
03-04 15:54 INFO     Training network 2
03-04 15:54 INFO     n_training: 78
03-04 15:54 INFO     Client: 2 Epoch: 0 Loss: 1.8010125144934044
03-04 15:54 INFO      ** Client: 2 Training complete **
03-04 15:54 INFO     Training network 3 n_training: 10000
03-04 15:54 INFO     Training network 3
03-04 15:54 INFO     n_training: 78
03-04 15:54 INFO     Client: 3 Epoch: 0 Loss: 1.7694938259247022
03-04 15:54 INFO      ** Client: 3 Training complete **
03-04 15:54 INFO     Training network 4 n_training: 10000
03-04 15:54 INFO     Training network 4
03-04 15:54 INFO     n_training: 78
03-04 15:54 INFO     Client: 4 Epoch: 0 Loss: 1.8071244083918059
03-04 15:54 INFO      ** Client: 4 Training complete **
03-04 15:54 INFO     global n_training: 390
03-04 15:54 INFO     global n_test: 79
03-04 15:54 INFO     >> Global Model Train accuracy: 0.124980
03-04 15:54 INFO     >> Global Model Test accuracy: 0.126300
03-04 15:54 INFO     >> Global Model Train loss: 2.257268
03-04 15:54 INFO     in comm round:5
03-04 15:54 INFO     Training network 0 n_training: 10000
03-04 15:54 INFO     Training network 0
03-04 15:54 INFO     n_training: 78
03-04 15:54 INFO     Client: 0 Epoch: 0 Loss: 1.8174004890979865
03-04 15:54 INFO      ** Client: 0 Training complete **
03-04 15:54 INFO     Training network 1 n_training: 10000
03-04 15:54 INFO     Training network 1
03-04 15:54 INFO     n_training: 78
03-04 15:54 INFO     Client: 1 Epoch: 0 Loss: 1.7776407186801617
03-04 15:54 INFO      ** Client: 1 Training complete **
03-04 15:54 INFO     Training network 2 n_training: 10000
03-04 15:54 INFO     Training network 2
03-04 15:54 INFO     n_training: 78
03-04 15:54 INFO     Client: 2 Epoch: 0 Loss: 1.7681015103291242
03-04 15:54 INFO      ** Client: 2 Training complete **
03-04 15:54 INFO     Training network 3 n_training: 10000
03-04 15:54 INFO     Training network 3
03-04 15:54 INFO     n_training: 78
03-04 15:54 INFO     Client: 3 Epoch: 0 Loss: 1.8352305400065887
03-04 15:54 INFO      ** Client: 3 Training complete **
03-04 15:54 INFO     Training network 4 n_training: 10000
03-04 15:54 INFO     Training network 4
03-04 15:54 INFO     n_training: 78
03-04 15:55 INFO     Client: 4 Epoch: 0 Loss: 1.763542624620291
03-04 15:55 INFO      ** Client: 4 Training complete **
03-04 15:55 INFO     global n_training: 390
03-04 15:55 INFO     global n_test: 79
03-04 15:55 INFO     >> Global Model Train accuracy: 0.197676
03-04 15:55 INFO     >> Global Model Test accuracy: 0.205000
03-04 15:55 INFO     >> Global Model Train loss: 2.134215
03-04 15:55 INFO     in comm round:6
03-04 15:55 INFO     Training network 0 n_training: 10000
03-04 15:55 INFO     Training network 0
03-04 15:55 INFO     n_training: 78
03-04 15:55 INFO     Client: 0 Epoch: 0 Loss: 1.6618447380188184
03-04 15:55 INFO      ** Client: 0 Training complete **
03-04 15:55 INFO     Training network 1 n_training: 10000
03-04 15:55 INFO     Training network 1
03-04 15:55 INFO     n_training: 78
03-04 15:55 INFO     Client: 1 Epoch: 0 Loss: 1.662296201938238
03-04 15:55 INFO      ** Client: 1 Training complete **
03-04 15:55 INFO     Training network 2 n_training: 10000
03-04 15:55 INFO     Training network 2
03-04 15:55 INFO     n_training: 78
03-04 15:55 INFO     Client: 2 Epoch: 0 Loss: 1.6828296031707373
03-04 15:55 INFO      ** Client: 2 Training complete **
03-04 15:55 INFO     Training network 3 n_training: 10000
03-04 15:55 INFO     Training network 3
03-04 15:55 INFO     n_training: 78
03-04 15:55 INFO     Client: 3 Epoch: 0 Loss: 1.6940035254527361
03-04 15:55 INFO      ** Client: 3 Training complete **
03-04 15:55 INFO     Training network 4 n_training: 10000
03-04 15:55 INFO     Training network 4
03-04 15:55 INFO     n_training: 78
03-04 15:55 INFO     Client: 4 Epoch: 0 Loss: 1.6796362980818138
03-04 15:55 INFO      ** Client: 4 Training complete **
03-04 15:55 INFO     global n_training: 390
03-04 15:55 INFO     global n_test: 79
03-04 15:55 INFO     >> Global Model Train accuracy: 0.355148
03-04 15:55 INFO     >> Global Model Test accuracy: 0.347800
03-04 15:55 INFO     >> Global Model Train loss: 1.720794
03-04 15:55 INFO     in comm round:7
03-04 15:55 INFO     Training network 0 n_training: 10000
03-04 15:55 INFO     Training network 0
03-04 15:55 INFO     n_training: 78
03-04 15:55 INFO     Client: 0 Epoch: 0 Loss: 1.5894347979472234
03-04 15:55 INFO      ** Client: 0 Training complete **
03-04 15:55 INFO     Training network 1 n_training: 10000
03-04 15:55 INFO     Training network 1
03-04 15:55 INFO     n_training: 78
03-04 15:55 INFO     Client: 1 Epoch: 0 Loss: 1.560911666124295
03-04 15:55 INFO      ** Client: 1 Training complete **
03-04 15:55 INFO     Training network 2 n_training: 10000
03-04 15:55 INFO     Training network 2
03-04 15:55 INFO     n_training: 78
03-04 15:55 INFO     Client: 2 Epoch: 0 Loss: 1.5828165320249705
03-04 15:55 INFO      ** Client: 2 Training complete **
03-04 15:55 INFO     Training network 3 n_training: 10000
03-04 15:55 INFO     Training network 3
03-04 15:55 INFO     n_training: 78
03-04 15:55 INFO     Client: 3 Epoch: 0 Loss: 1.576372573008904
03-04 15:55 INFO      ** Client: 3 Training complete **
03-04 15:55 INFO     Training network 4 n_training: 10000
03-04 15:55 INFO     Training network 4
03-04 15:55 INFO     n_training: 78
03-04 15:55 INFO     Client: 4 Epoch: 0 Loss: 1.6050259593205574
03-04 15:55 INFO      ** Client: 4 Training complete **
03-04 15:55 INFO     global n_training: 390
03-04 15:55 INFO     global n_test: 79
03-04 15:55 INFO     >> Global Model Train accuracy: 0.399980
03-04 15:55 INFO     >> Global Model Test accuracy: 0.398900
03-04 15:55 INFO     >> Global Model Train loss: 1.599608
03-04 15:55 INFO     in comm round:8
03-04 15:55 INFO     Training network 0 n_training: 10000
03-04 15:55 INFO     Training network 0
03-04 15:55 INFO     n_training: 78
03-04 15:55 INFO     Client: 0 Epoch: 0 Loss: 1.490519833870423
03-04 15:55 INFO      ** Client: 0 Training complete **
03-04 15:55 INFO     Training network 1 n_training: 10000
03-04 15:55 INFO     Training network 1
03-04 15:55 INFO     n_training: 78
03-04 15:56 INFO     Client: 1 Epoch: 0 Loss: 1.5011079601752453
03-04 15:56 INFO      ** Client: 1 Training complete **
03-04 15:56 INFO     Training network 2 n_training: 10000
03-04 15:56 INFO     Training network 2
03-04 15:56 INFO     n_training: 78
03-04 15:56 INFO     Client: 2 Epoch: 0 Loss: 1.4914606213569641
03-04 15:56 INFO      ** Client: 2 Training complete **
03-04 15:56 INFO     Training network 3 n_training: 10000
03-04 15:56 INFO     Training network 3
03-04 15:56 INFO     n_training: 78
03-04 15:56 INFO     Client: 3 Epoch: 0 Loss: 1.4714273672837477
03-04 15:56 INFO      ** Client: 3 Training complete **
03-04 15:56 INFO     Training network 4 n_training: 10000
03-04 15:56 INFO     Training network 4
03-04 15:56 INFO     n_training: 78
03-04 15:56 INFO     Client: 4 Epoch: 0 Loss: 1.4974316893479762
03-04 15:56 INFO      ** Client: 4 Training complete **
03-04 15:56 INFO     global n_training: 390
03-04 15:56 INFO     global n_test: 79
03-04 15:56 INFO     >> Global Model Train accuracy: 0.494972
03-04 15:56 INFO     >> Global Model Test accuracy: 0.497000
03-04 15:56 INFO     >> Global Model Train loss: 1.398419
03-04 15:56 INFO     in comm round:9
03-04 15:56 INFO     Training network 0 n_training: 10000
03-04 15:56 INFO     Training network 0
03-04 15:56 INFO     n_training: 78
03-04 15:56 INFO     Client: 0 Epoch: 0 Loss: 1.3953040272761614
03-04 15:56 INFO      ** Client: 0 Training complete **
03-04 15:56 INFO     Training network 1 n_training: 10000
03-04 15:56 INFO     Training network 1
03-04 15:56 INFO     n_training: 78
03-04 15:56 INFO     Client: 1 Epoch: 0 Loss: 1.3930505300179505
03-04 15:56 INFO      ** Client: 1 Training complete **
03-04 15:56 INFO     Training network 2 n_training: 10000
03-04 15:56 INFO     Training network 2
03-04 15:56 INFO     n_training: 78
03-04 15:56 INFO     Client: 2 Epoch: 0 Loss: 1.3901946911445031
03-04 15:56 INFO      ** Client: 2 Training complete **
03-04 15:56 INFO     Training network 3 n_training: 10000
03-04 15:56 INFO     Training network 3
03-04 15:56 INFO     n_training: 78
03-04 15:56 INFO     Client: 3 Epoch: 0 Loss: 1.3956169516612322
03-04 15:56 INFO      ** Client: 3 Training complete **
03-04 15:56 INFO     Training network 4 n_training: 10000
03-04 15:56 INFO     Training network 4
03-04 15:56 INFO     n_training: 78
03-04 15:56 INFO     Client: 4 Epoch: 0 Loss: 1.3990983366966248
03-04 15:56 INFO      ** Client: 4 Training complete **
03-04 15:56 INFO     global n_training: 390
03-04 15:56 INFO     global n_test: 79
03-04 15:56 INFO     >> Global Model Train accuracy: 0.502784
03-04 15:56 INFO     >> Global Model Test accuracy: 0.500200
03-04 15:56 INFO     >> Global Model Train loss: 1.362046
